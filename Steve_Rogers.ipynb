{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from keras.layers import Dense,Dropout,LSTM,Embedding,BatchNormalization,Activation\n",
    "from keras.models import Sequential\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as py\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from keras.models import load_model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.optimizers import RMSprop\n",
    "import pandas as pd\n",
    "import re\n",
    "%matplotlib inline\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Venky\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Venky\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p2=pd.read_json('Sarcasm_Headlines_Dataset.json',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_link  \\\n",
       "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
       "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
       "2  https://local.theonion.com/mom-starting-to-fea...   \n",
       "3  https://politics.theonion.com/boehner-just-wan...   \n",
       "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
       "\n",
       "                                            headline  is_sarcastic  \n",
       "0  former versace store clerk sues over secret 'b...             0  \n",
       "1  the 'roseanne' revival catches up to our thorn...             0  \n",
       "2  mom starting to fear son's web series closest ...             1  \n",
       "3  boehner just wants wife to listen, not come up...             1  \n",
       "4  j.k. rowling wishes snape happy birthday in th...             0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.huffingtonpost.com/entry/obama-veterans-day_us_564372e9e4b08cda3486f09b'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2[p2['is_sarcastic']==0]\n",
    "p2.iloc[26,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2.drop('article_link',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2['headline']=p2['headline'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEKCAYAAADaa8itAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAG+9JREFUeJzt3X+YXVV97/H3x0QEUiBBZMqTRBNtao3QVhwh1l47EoVAW4JerKG0BG9q7oPR/pBWg/Y2FuS5ci2lgopGyU3ACCJVkxYsRuTI9ZbfPyT8kJsRYhhB0SZEBxQa/N4/9jo8h8mZzM6ZdfbmzHxezzPP7L322md9v5Nkvtl7r7OOIgIzM7McXlB3AGZmNnG4qJiZWTYuKmZmlo2LipmZZeOiYmZm2biomJlZNi4qZmaWjYuKmZll46JiZmbZTK07gKodcsghMWfOnI7OfeKJJ5g2bVregJ7nnPPkMNlynmz5wvhzvv32238SES8Zq9+kKypz5szhtttu6+jcRqPBwMBA3oCe55zz5DDZcp5s+cL4c5b0/TL9fPvLzMyycVExM7NsXFTMzCwbFxUzM8vGRcXMzLJxUTEzs2xcVMzMLBsXFTMzy8ZFxczMspl076gfj80/2MnpK6+ufNytH/39ysc0M+uEr1TMzCwbFxUzM8vGRcXMzLJxUTEzs2xcVMzMLBsXFTMzy8ZFxczMsnFRMTOzbFxUzMwsm64VFUlrJD0m6Z42x/5aUkg6JO1L0oWSBiXdLenIlr5LJW1JX0tb2l8raXM650JJ6lYuZmZWTjevVNYCi0Y2SpoNvAXY1tJ8PDAvfS0HLk59DwZWAUcDRwGrJM1I51yc+jbP220sMzOrVteKSkTcAGxvc+gC4P1AtLQtBi6Nwk3AdEmHAccBmyJie0TsADYBi9KxAyPixogI4FLgpG7lYmZm5VS6oKSkE4EfRMR3Rtytmgk83LI/lNr21D7Upn20cZdTXNXQ19dHo9HoKP6+/eDMI3Z1dO54dBpvDsPDw7WOXwfnPPFNtnyhupwrKyqS9gc+BBzb7nCbtuigva2IWA2sBujv74+BgYGxwm3rovUbOH9z9Qs7bz11oPIxmxqNBp3+vHqVc574Jlu+UF3OVc7+egUwF/iOpK3ALOAOSb9KcaUxu6XvLOCRMdpntWk3M7MaVVZUImJzRBwaEXMiYg5FYTgyIn4IbAROS7PAFgA7I+JR4FrgWEkz0gP6Y4Fr07GfSVqQZn2dBmyoKhczM2uvm1OKLwduBF4paUjSsj10vwZ4EBgEPgu8GyAitgPnALemr7NTG8AZwOfSOd8DvtaNPMzMrLyuPSCIiFPGOD6nZTuAFaP0WwOsadN+G3D4+KI0M7Oc/I56MzPLxkXFzMyycVExM7NsXFTMzCwbFxUzM8vGRcXMzLJxUTEzs2xcVMzMLBsXFTMzy8ZFxczMsnFRMTOzbFxUzMwsGxcVMzPLxkXFzMyycVExM7NsXFTMzCwbFxUzM8vGRcXMzLLp5mfUr5H0mKR7Wto+Jum7ku6W9BVJ01uOnSVpUNIDko5raV+U2gYlrWxpnyvpZklbJH1R0j7dysXMzMrp5pXKWmDRiLZNwOER8ZvA/wPOApA0H1gCvDqd8ylJUyRNAT4JHA/MB05JfQHOAy6IiHnADmBZF3MxM7MSulZUIuIGYPuItq9HxK60exMwK20vBq6IiKci4iFgEDgqfQ1GxIMR8TRwBbBYkoBjgKvS+euAk7qVi5mZlVPnM5X/Bnwtbc8EHm45NpTaRmt/MfB4S4FqtpuZWY2m1jGopA8Bu4D1zaY23YL2RS/20H+08ZYDywH6+vpoNBp7E+6z+vaDM4/YNXbHzDqNN4fh4eFax6+Dc574Jlu+UF3OlRcVSUuBPwAWRkSzEAwBs1u6zQIeSdvt2n8CTJc0NV2ttPbfTUSsBlYD9Pf3x8DAQEexX7R+A+dvrr4Obz11oPIxmxqNBp3+vHqVc574Jlu+UF3Old7+krQI+ABwYkQ82XJoI7BE0oskzQXmAbcAtwLz0kyvfSge5m9Mxeh64OR0/lJgQ1V5mJlZe92cUnw5cCPwSklDkpYBnwAOADZJukvSpwEi4l7gSuA+4N+AFRHxTLoKeQ9wLXA/cGXqC0Vxep+kQYpnLJd0KxczMyuna/dyIuKUNs2j/uKPiHOBc9u0XwNc06b9QYrZYWZmPWPOyqtrGXftommVjON31JuZWTYuKmZmlo2LipmZZeOiYmZm2biomJlZNi4qZmaWjYuKmZll46JiZmbZuKiYmVk2LipmZpaNi4qZmWXjomJmZtm4qJiZWTYuKmZmlo2LipmZZeOiYmZm2biomJlZNi4qZmaWjYuKmZll07WiImmNpMck3dPSdrCkTZK2pO8zUrskXShpUNLdko5sOWdp6r9F0tKW9tdK2pzOuVCSupWLmZmV080rlbXAohFtK4HrImIecF3aBzgemJe+lgMXQ1GEgFXA0cBRwKpmIUp9lrecN3IsMzOrWNeKSkTcAGwf0bwYWJe21wEntbRfGoWbgOmSDgOOAzZFxPaI2AFsAhalYwdGxI0REcClLa9lZmY1qfqZSl9EPAqQvh+a2mcCD7f0G0pte2ofatNuZmY1mlp3AEm75yHRQXv7F5eWU9wqo6+vj0aj0UGI0LcfnHnEro7OHY9O481heHi41vHr4JwnvjrzreN3CFSXc9VF5UeSDouIR9MtrMdS+xAwu6XfLOCR1D4wor2R2me16d9WRKwGVgP09/fHwMDAaF336KL1Gzh/c/V1eOupA5WP2dRoNOj059WrnPPEV2e+p6+8upZx1y6aVknOVd/+2gg0Z3AtBTa0tJ+WZoEtAHam22PXAsdKmpEe0B8LXJuO/UzSgjTr67SW1zIzs5p07b/dki6nuMo4RNIQxSyujwJXSloGbAPenrpfA5wADAJPAu8EiIjtks4Bbk39zo6I5sP/MyhmmO0HfC19mZlZjbpWVCLilFEOLWzTN4AVo7zOGmBNm/bbgMPHE6OZmeVV6vaXJP/yNjOzMZV9pvJpSbdIerek6V2NyMzMelapohIRvwucSjFD6zZJX5D0lq5GZmZmPaf07K+I2AL8LfAB4PeACyV9V9LbuhWcmZn1lrLPVH5T0gXA/cAxwB9GxKvS9gVdjM/MzHpI2dlfnwA+C3wwIn7ebIyIRyT9bVciMzOznlO2qJwA/DwingGQ9AJg34h4MiIu61p0ZmbWU8o+U/kGxZsMm/ZPbWZmZs8qW1T2jYjh5k7a3r87IZmZWa8qW1SeGPFpjK8Ffr6H/mZmNgmVfabyl8CXJDVXAj4MeEd3QjIzs15VqqhExK2SfgN4JcVnmXw3Iv6zq5GZmVnP2ZsFJV8HzEnnvEYSEXFpV6IyM7OeVKqoSLoMeAVwF/BMam5+NryZmRlQ/kqlH5iflqg3MzNrq+zsr3uAX+1mIGZm1vvKXqkcAtwn6RbgqWZjRJzYlajMzKwnlS0qH+5mEGZmNjGUnVL8LUkvA+ZFxDck7Q9M6W5oZmbWa8ouff8u4CrgM6lpJvDVTgeV9FeS7pV0j6TLJe0raa6kmyVtkfRFSfukvi9K+4Pp+JyW1zkrtT8g6bhO4zEzszzKPqhfAbwB+Ck8+4Fdh3YyoKSZwJ8D/RFxOMUVzxLgPOCCiJgH7ACWpVOWATsi4tcoPrvlvPQ689N5rwYWAZ+S5KsnM7MalS0qT0XE080dSVMp3qfSqanAful19gcepfjAr6vS8XXASWl7cdonHV8oSan9ioh4KiIeAgaBo8YRk5mZjVPZB/XfkvRBikLwFuDdwL90MmBE/EDSPwDbKBal/DpwO/B4ROxK3YYobrGRvj+czt0laSfw4tR+U8tLt57zHJKWA8sB+vr6aDQanYRO335w5hG7xu6YWafx5jA8PFzr+HVwzhNfnfnW8TsEqsu5bFFZSXEbajPw34FrgM91MqCkGRRXGXOBx4EvAce36dq8EtIox0Zr370xYjWwGqC/vz8GBgb2LujkovUbOH/z3qxsk8fWUwcqH7Op0WjQ6c+rVznnia/OfE9feXUt465dNK2SnMvO/volxccJfzbDmG8GHoqIHwNI+jLwO8B0SVPT1cosoLki8hAwGxhKt8sOAra3tDe1nmNmZjUoO/vrIUkPjvzqcMxtwAJJ+6dnIwuB+4DrgZNTn6XAhrS9Me2Tjn8zLRezEViSZofNBeYBt3QYk5mZZbA3a3817Qu8HTi4kwEj4mZJVwF3ALuAOyluTV0NXCHpI6ntknTKJcBlkgYprlCWpNe5V9KVFAVpF7AiIp7BzMxqU/b213+MaPonSd8G/q6TQSNiFbBqRPODtJm9FRG/oChi7V7nXODcTmIwM7P8yi59f2TL7gsorlwO6EpEZmbWs8re/jq/ZXsXsBX4o+zRmJlZTyt7++tN3Q7EzMx6X9nbX+/b0/GI+Mc84ZiZWS/bm9lfr6OYxgvwh8ANpHe6m5mZwd59SNeREfEzAEkfBr4UEX/WrcDMzKz3lF1Q8qXA0y37TwNzskdjZmY9reyVymXALZK+QrG+1luBS7sWlZmZ9aSys7/OlfQ14L+kpndGxJ3dC8vMzHpR2dtfUHzuyU8j4uMUizvO7VJMZmbWo8ouKLkK+ABwVmp6IfD5bgVlZma9qeyVyluBE4EnACLiEbxMi5mZjVC2qDydlpsPAEnTuheSmZn1qrJF5UpJn6H4IK13Ad8gzwd2mZnZBFJ29tc/pM+m/ynwSuDvImJTVyMzM7OeM2ZRkTQFuDYi3gy4kJiZ2ajGvP2VPk3xSUkHVRCPmZn1sLLvqP8FsFnSJtIMMICI+POuRGVmZj2p7IP6q4H/QbEy8e0tXx2RNF3SVZK+K+l+Sa+XdLCkTZK2pO8zUl9JulDSoKS7Wz+FUtLS1H+LpKWdxmNmZnns8UpF0ksjYltErMs87seBf4uIkyXtQ/Fu/Q8C10XERyWtBFZSvOHyeGBe+joauBg4WtLBFJ9z308x1fl2SRsjYkfmWM3MrKSxrlS+2tyQ9M85BpR0IPBG4BKAiHg6Ih4HFgPN4rUOOCltLwYujcJNFNOaDwOOAzZFxPZUSDYBi3LEaGZmnRmrqKhl++WZxnw58GPgf0u6U9Ln0psp+yLiUYD0/dDUfybP/TCwodQ2WruZmdVkrAf1Mcr2eMc8EnhvRNws6eMUt7pGozZtsYf23V9AWg4sB+jr66PRaOxVwE19+8GZR+zq6Nzx6DTeHIaHh2sdvw7OeeKrM986fodAdTmPVVR+S9JPKX6B75e2SfsREQd2MOYQMBQRN6f9qyiKyo8kHRYRj6bbW4+19J/dcv4s4JHUPjCivdFuwIhYDawG6O/vj4GBgXbdxnTR+g2cv7nshLl8tp46UPmYTY1Gg05/Xr3KOU98deZ7+sqraxl37aJpleS8x9tfETElIg6MiAMiYmrabu53UlCIiB8CD0t6ZWpaCNwHbASaM7iWAhvS9kbgtDQLbAGwM90euxY4VtKMNFPs2NRmZmY1qf6/3YX3AuvTzK8HgXdSFLgrJS0DtgFvT32vAU4ABoEnU18iYrukc4BbU7+zI2J7dSmYmdlItRSViLiLYirwSAvb9A1gxSivswZYkzc6MzPr1N588qOZmdkeuaiYmVk2LipmZpaNi4qZmWXjomJmZtm4qJiZWTYuKmZmlo2LipmZZeOiYmZm2biomJlZNi4qZmaWjYuKmZll46JiZmbZuKiYmVk2LipmZpaNi4qZmWXjomJmZtm4qJiZWTYuKmZmlk1tRUXSFEl3SvrXtD9X0s2Stkj6oqR9UvuL0v5gOj6n5TXOSu0PSDqunkzMzKypziuVvwDub9k/D7ggIuYBO4BlqX0ZsCMifg24IPVD0nxgCfBqYBHwKUlTKordzMzaqKWoSJoF/D7wubQv4BjgqtRlHXBS2l6c9knHF6b+i4ErIuKpiHgIGASOqiYDMzNrp64rlX8C3g/8Mu2/GHg8Inal/SFgZtqeCTwMkI7vTP2fbW9zjpmZ1WBq1QNK+gPgsYi4XdJAs7lN1xjj2J7OGTnmcmA5QF9fH41GY29CflbffnDmEbvG7phZp/HmMDw8XOv4dXDOE1+d+dbxOwSqy7nyogK8AThR0gnAvsCBFFcu0yVNTVcjs4BHUv8hYDYwJGkqcBCwvaW9qfWc54iI1cBqgP7+/hgYGOgo8IvWb+D8zdX/yLaeOlD5mE2NRoNOf169yjlPfHXme/rKq2sZd+2iaZXkXPntr4g4KyJmRcQcigft34yIU4HrgZNTt6XAhrS9Me2Tjn8zIiK1L0mzw+YC84BbKkrDzMzaqONKZTQfAK6Q9BHgTuCS1H4JcJmkQYorlCUAEXGvpCuB+4BdwIqIeKb6sM3MrKnWohIRDaCRth+kzeytiPgF8PZRzj8XOLd7EZqZ2d7wO+rNzCwbFxUzM8vGRcXMzLJxUTEzs2xcVMzMLBsXFTMzy8ZFxczMsnFRMTOzbFxUzMwsGxcVMzPLxkXFzMyycVExM7NsXFTMzCwbFxUzM8vGRcXMzLJxUTEzs2xcVMzMLBsXFTMzy8ZFxczMsqm8qEiaLel6SfdLulfSX6T2gyVtkrQlfZ+R2iXpQkmDku6WdGTLay1N/bdIWlp1LmZm9lx1XKnsAs6MiFcBC4AVkuYDK4HrImIecF3aBzgemJe+lgMXQ1GEgFXA0cBRwKpmITIzs3pUXlQi4tGIuCNt/wy4H5gJLAbWpW7rgJPS9mLg0ijcBEyXdBhwHLApIrZHxA5gE7CowlTMzGyEqXUOLmkO8BrgZqAvIh6FovBIOjR1mwk83HLaUGobrb3dOMsprnLo6+uj0Wh0FG/ffnDmEbs6Onc8Oo03h+Hh4VrHr4NznvjqzLeO3yFQXc61FRVJvwL8M/CXEfFTSaN2bdMWe2jfvTFiNbAaoL+/PwYGBvY6XoCL1m/g/M3V/8i2njpQ+ZhNjUaDTn9evco5T3x15nv6yqtrGXftommV5FzL7C9JL6QoKOsj4sup+Ufpthbp+2OpfQiY3XL6LOCRPbSbmVlN6pj9JeAS4P6I+MeWQxuB5gyupcCGlvbT0iywBcDOdJvsWuBYSTPSA/pjU5uZmdWkjttfbwD+FNgs6a7U9kHgo8CVkpYB24C3p2PXACcAg8CTwDsBImK7pHOAW1O/syNiezUpmJlZO5UXlYj4Nu2fhwAsbNM/gBWjvNYaYE2+6MzMbDz8jnozM8vGRcXMzLJxUTEzs2xcVMzMLBsXFTMzy8ZFxczMsnFRMTOzbFxUzMwsGxcVMzPLxkXFzMyycVExM7NsXFTMzCwbFxUzM8vGRcXMzLJxUTEzs2xcVMzMLBsXFTMzy8ZFxczMsun5oiJpkaQHJA1KWll3PGZmk1lPFxVJU4BPAscD84FTJM2vNyozs8mrp4sKcBQwGBEPRsTTwBXA4ppjMjObtHq9qMwEHm7ZH0ptZmZWg6l1BzBOatMWu3WSlgPL0+6wpAc6HO8Q4CcdntsxnVf1iM9RS841c84T32TLlzedN+6cX1amU68XlSFgdsv+LOCRkZ0iYjWweryDSbotIvrH+zq9xDlPDpMt58mWL1SXc6/f/roVmCdprqR9gCXAxppjMjObtHr6SiUidkl6D3AtMAVYExH31hyWmdmk1dNFBSAirgGuqWi4cd9C60HOeXKYbDlPtnyhopwVsdtzbTMzs470+jMVMzN7HnFRaWOspV8kvUjSF9PxmyXNqT7KfErk+z5J90m6W9J1kkpNLXw+K7u8j6STJYWknp8pVCZnSX+U/qzvlfSFqmPMrcTf7ZdKul7Snenv9wl1xJmLpDWSHpN0zyjHJenC9PO4W9KR2YOICH+1fFE88P8e8HJgH+A7wPwRfd4NfDptLwG+WHfcXc73TcD+afuMXs63bM6p3wHADcBNQH/dcVfw5zwPuBOYkfYPrTvuCnJeDZyRtucDW+uOe5w5vxE4ErhnlOMnAF+jeI/fAuDm3DH4SmV3ZZZ+WQysS9tXAQsltXsjZi8YM9+IuD4inky7N1G8H6iXlV3e5xzgfwG/qDK4LimT87uAT0bEDoCIeKziGHMrk3MAB6btg2jzPrdeEhE3ANv30GUxcGkUbgKmSzosZwwuKrsrs/TLs30iYhewE3hxJdHlt7dL3Syj+J9OLxszZ0mvAWZHxL9WGVgXlflz/nXg1yX9X0k3SVpUWXTdUSbnDwN/ImmIYhbpe6sJrTZdX9qq56cUd0GZpV9KLQ/TI0rnIulPgH7g97oaUfftMWdJLwAuAE6vKqAKlPlznkpxC2yA4mr0/0g6PCIe73Js3VIm51OAtRFxvqTXA5elnH/Z/fBq0fXfXb5S2V2ZpV+e7SNpKsVl854uOZ/PSi11I+nNwIeAEyPiqYpi65axcj4AOBxoSNpKce95Y48/rC/793pDRPxnRDwEPEBRZHpVmZyXAVcCRMSNwL4U64JNVKX+vY+Hi8ruyiz9shFYmrZPBr4Z6SlYDxoz33Qr6DMUBaXX77PDGDlHxM6IOCQi5kTEHIrnSCdGxG31hJtFmb/XX6WYlIGkQyhuhz1YaZR5lcl5G7AQQNKrKIrKjyuNslobgdPSLLAFwM6IeDTnAL79NUKMsvSLpLOB2yJiI3AJxWXyIMUVypL6Ih6fkvl+DPgV4EtpPsK2iDixtqDHqWTOE0rJnK8FjpV0H/AM8DcR8R/1RT0+JXM+E/ispL+iuA10eg//BxFJl1PcvjwkPSdaBbwQICI+TfHc6ARgEHgSeGf2GHr452dmZs8zvv1lZmbZuKiYmVk2LipmZpaNi4qZmWXjomJmZtm4qJglkvokfUHSg5Jul3SjpLfWEMfW9D6R1rabJd0laZukH6ftu/ZmhWxJx6T3JjT3Py/ppHyRm/l9KmZAsSQ4xZv/1kXEH6e2lwG7vR9H0tS05ltlIuLoNPbpFCsmv6ddP0lTIuKZUV7mGOAnFG/mNOsKX6mYFY4Bnk5vEAMgIr4fERdB8ctc0pck/Qvw9fSO5I9JukfSZknvSP0GJD27CKWkT6RC0LwC+XtJd6RzfiO1v1jS19NnenyG9usztSVpqqTHJX1E0i3AUZKGJE1PxxdI+oakVwB/BvxNusL5nfQSb5L07+nqrPKrMpt4XFTMCq8G7hijz+uBpRFxDPA24LeB3wLeDHys5BLiP4mII4GLgb9ObauAb0fEayiW0XjpXsZ+EHBHRByV1q/aTUR8D/gc8LGI+O2I+Pd06FDgDcBJwP/cy3HNduOiYtaGpE9K+o6kW1uaN0VEc+HQ3wUuj4hnIuJHwLeA15V46S+n77cDc9L2G4HPA0TE1cCOvQz3aeAre3lO01fTZ2vcTeYl0G1yclExK9xL8Yl5AETECoqFBl/S0ueJlu3RblHt4rn/rvYdcby5wvMzPPeZ5njWS/r5iPWqWmMYOf5IrStO9+oHzdnziIuKWeGbwL6Szmhp238P/W8A3iFpiqSXUFxt3AJ8H5gv6UWSDiKtgDuGG4BTASQdD8zoJIEWW4HXpu3/2tL+M4pl/c26xrO/zICIiDS99gJJ76dY/vwJ4AOjnPIVimcs36G4ynh/RPwQQNKVwN3AForPfB/L3wOXS7qD4jbatvHkQvFphp+V9EOKQte0gWKl6bcBK8Y5hllbXqXYzMyy8e0vMzPLxkXFzMyycVExM7NsXFTMzCwbFxUzM8vGRcXMzLJxUTEzs2xcVMzMLJv/D7JGaxj7RS0tAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p2['is_sarcastic'].hist()\n",
    "py.xlabel('Ground Truth')\n",
    "py.ylabel('Frequency')\n",
    "py.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,x_test,Y_train,y_test=train_test_split(pd.DataFrame(p2['headline']),pd.DataFrame(p2['is_sarcastic']),test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 21367/21367 [00:10<00:00, 2120.21it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 5342/5342 [00:01<00:00, 3662.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21367\n",
      "5342\n"
     ]
    }
   ],
   "source": [
    "def clean_sentences(df):\n",
    "    clean = []\n",
    "    \n",
    "    for sent in tqdm(df['headline']):\n",
    "\n",
    "        #remove non-alphabetic characters\n",
    "        cleaned_text = re.sub(\"[^a-zA-Z]\",\" \", sent)\n",
    "    \n",
    "        #tokenize the sentences\n",
    "        words = word_tokenize(cleaned_text.lower())\n",
    "    \n",
    "        #lemmatize each word to its lemma\n",
    "        lemma_words = [lemmatizer.lemmatize(i) for i in words]\n",
    "    \n",
    "        clean.append(lemma_words)\n",
    "\n",
    "    return(clean)\n",
    "train=X_train\n",
    "test=x_test\n",
    "\n",
    "#cleaned reviews for both train and test set retrieved\n",
    "train_sentences = clean_sentences(train)\n",
    "test_sentences = clean_sentences(test)\n",
    "\n",
    "print(len(train_sentences))\n",
    "print(len(test_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=Y_train.is_sarcastic.values\n",
    "y_target=to_categorical(target)\n",
    "num_classes=y_target.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_val,y_train,y_val=train_test_split(train_sentences,Y_train,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 17093/17093 [00:00<00:00, 510948.57it/s]\n"
     ]
    }
   ],
   "source": [
    "unique_words = set()\n",
    "len_max = 0\n",
    "\n",
    "for sent in tqdm(x_train):\n",
    "    \n",
    "    unique_words.update(sent)\n",
    "    \n",
    "    if(len_max<len(sent)):\n",
    "        len_max = len(sent)\n",
    "tokenizer = Tokenizer(num_words=len(list(unique_words)))\n",
    "tokenizer.fit_on_texts(list(x_train))\n",
    "x_train = tokenizer.texts_to_sequences(x_train)\n",
    "x_val = tokenizer.texts_to_sequences(x_val)\n",
    "x_test = tokenizer.texts_to_sequences(test_sentences)\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=len_max)\n",
    "x_val = sequence.pad_sequences(x_val, maxlen=len_max)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=len_max)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Venky\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Venky\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Venky\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=rf.predict(x_train)\n",
    "y_pred1=rf.predict(x_val)\n",
    "y_pred2=rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Logistic Regression --------------\n",
      "\n",
      "Training accuracy = 0.5920552272860236 \n",
      "Validation accuracy= 0.5732335049134301 \n",
      "Testing Accuracy= 0.5780606514414077\n"
     ]
    }
   ],
   "source": [
    "print('--------------- Logistic Regression --------------\\n')\n",
    "print('Training accuracy = {s2} \\nValidation accuracy= {s1} \\nTesting Accuracy= {s3}'.format(s1=accuracy_score(y_val,y_pred1),s2=accuracy_score(y_train,y_pred),s3=accuracy_score(y_test,y_pred2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes using MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Venky\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=rf.predict(x_train)\n",
    "y_pred1=rf.predict(x_val)\n",
    "y_pred2=rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Naive Bayes --------------\n",
      "\n",
      "Training accuracy = 0.5294565026619084 \n",
      "Validation accuracy= 0.5271408516612073 \n",
      "Testing Accuracy= 0.5183451890677648\n"
     ]
    }
   ],
   "source": [
    "print('--------------- Naive Bayes --------------\\n')\n",
    "print('Training accuracy = {s2} \\nValidation accuracy= {s1} \\nTesting Accuracy= {s3}'.format(s1=accuracy_score(y_val,y_pred1),s2=accuracy_score(y_train,y_pred),s3=accuracy_score(y_test,y_pred2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.48      0.53      3012\n",
      "           1       0.46      0.57      0.51      2330\n",
      "\n",
      "   micro avg       0.52      0.52      0.52      5342\n",
      "   macro avg       0.52      0.52      0.52      5342\n",
      "weighted avg       0.53      0.52      0.52      5342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1432 1580]\n",
      " [ 993 1337]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Venky\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Venky\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=rf.predict(x_train)\n",
    "y_pred1=rf.predict(x_val)\n",
    "y_pred2=rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Random Forest Classifier --------------\n",
      "\n",
      "Training accuracy = 0.9850816123559352 \n",
      "Validation accuracy= 0.6228357510528779 \n",
      "Testing Accuracy= 0.6205540995881692\n"
     ]
    }
   ],
   "source": [
    "print('--------------- Random Forest Classifier --------------\\n')\n",
    "print('Training accuracy = {s2} \\nValidation accuracy= {s1} \\nTesting Accuracy= {s3}'.format(s1=accuracy_score(y_val,y_pred1),s2=accuracy_score(y_train,y_pred),s3=accuracy_score(y_test,y_pred2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=SVC(C=1e+8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Venky\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Venky\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=100000000.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=rf.predict(x_train)\n",
    "y_pred1=rf.predict(x_val)\n",
    "y_pred2=rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- SVM --------------\n",
      "\n",
      "Training accuracy = 1.0 \n",
      "Validation accuracy= 0.5615348619560131 \n",
      "Testing Accuracy= 0.5627105952826656\n"
     ]
    }
   ],
   "source": [
    "print('--------------- SVM --------------\\n')\n",
    "print('Training accuracy = {s2} \\nValidation accuracy= {s1} \\nTesting Accuracy= {s3}'.format(s1=accuracy_score(y_val,y_pred1),s2=accuracy_score(y_train,y_pred),s3=accuracy_score(y_test,y_pred2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_val,y_train,y_val=train_test_split(train_sentences,y_target,test_size=0.2)  #y_target for LSTM,Y_train for traditional models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 17093/17093 [00:00<00:00, 489290.14it/s]\n"
     ]
    }
   ],
   "source": [
    "unique_words = set()\n",
    "len_max = 0\n",
    "for sent in tqdm(x_train):\n",
    "    unique_words.update(sent)\n",
    "    if(len_max<len(sent)):\n",
    "        len_max = len(sent)\n",
    "tokenizer = Tokenizer(num_words=len(list(unique_words)))\n",
    "tokenizer.fit_on_texts(list(x_train))\n",
    "x_train = tokenizer.texts_to_sequences(x_train)\n",
    "x_val = tokenizer.texts_to_sequences(x_val)\n",
    "x_test = tokenizer.texts_to_sequences(test_sentences)\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=len_max)\n",
    "x_val = sequence.pad_sequences(x_val, maxlen=len_max)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=len_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Venky\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Venky\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "ml=Sequential()\n",
    "ml.add(Embedding(len(list(unique_words)),300,input_length=len_max))\n",
    "ml.add(LSTM(64,dropout=0.5, recurrent_dropout=0.5,return_sequences=True))\n",
    "ml.add(LSTM(32,dropout=0.5, recurrent_dropout=0.5,return_sequences=False))\n",
    "ml.add(Dense(50,activation='relu'))\n",
    "ml.add(Dropout(0.5))\n",
    "ml.add(Dense(50))\n",
    "ml.add(BatchNormalization())\n",
    "ml.add(Activation('relu'))\n",
    "ml.add(Dense(50,activation='relu'))\n",
    "ml.add(Dense(num_classes,activation='softmax'))\n",
    "ml.compile(optimizer=RMSprop(lr=0.01),metrics=['accuracy'],loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Venky\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 17093 samples, validate on 4274 samples\n",
      "Epoch 1/2\n",
      "17093/17093 [==============================] - ETA: 8:08 - loss: 0.7358 - acc: 0.436 - ETA: 4:10 - loss: 1.0211 - acc: 0.478 - ETA: 2:50 - loss: 0.9835 - acc: 0.482 - ETA: 2:10 - loss: 0.9213 - acc: 0.492 - ETA: 1:46 - loss: 0.8819 - acc: 0.494 - ETA: 1:29 - loss: 0.8496 - acc: 0.506 - ETA: 1:18 - loss: 0.8315 - acc: 0.508 - ETA: 1:09 - loss: 0.8152 - acc: 0.512 - ETA: 1:02 - loss: 0.8013 - acc: 0.515 - ETA: 57s - loss: 0.7879 - acc: 0.525 - ETA: 52s - loss: 0.7811 - acc: 0.52 - ETA: 48s - loss: 0.7741 - acc: 0.52 - ETA: 45s - loss: 0.7669 - acc: 0.53 - ETA: 42s - loss: 0.7621 - acc: 0.53 - ETA: 39s - loss: 0.7569 - acc: 0.53 - ETA: 37s - loss: 0.7539 - acc: 0.53 - ETA: 35s - loss: 0.7493 - acc: 0.53 - ETA: 33s - loss: 0.7470 - acc: 0.53 - ETA: 32s - loss: 0.7447 - acc: 0.53 - ETA: 30s - loss: 0.7427 - acc: 0.53 - ETA: 29s - loss: 0.7405 - acc: 0.53 - ETA: 27s - loss: 0.7385 - acc: 0.53 - ETA: 26s - loss: 0.7364 - acc: 0.53 - ETA: 25s - loss: 0.7347 - acc: 0.53 - ETA: 24s - loss: 0.7332 - acc: 0.53 - ETA: 23s - loss: 0.7319 - acc: 0.53 - ETA: 22s - loss: 0.7306 - acc: 0.53 - ETA: 21s - loss: 0.7290 - acc: 0.53 - ETA: 20s - loss: 0.7286 - acc: 0.53 - ETA: 19s - loss: 0.7272 - acc: 0.53 - ETA: 18s - loss: 0.7258 - acc: 0.53 - ETA: 18s - loss: 0.7248 - acc: 0.53 - ETA: 17s - loss: 0.7238 - acc: 0.53 - ETA: 16s - loss: 0.7226 - acc: 0.53 - ETA: 15s - loss: 0.7213 - acc: 0.53 - ETA: 15s - loss: 0.7208 - acc: 0.53 - ETA: 14s - loss: 0.7201 - acc: 0.53 - ETA: 13s - loss: 0.7193 - acc: 0.53 - ETA: 13s - loss: 0.7184 - acc: 0.53 - ETA: 12s - loss: 0.7179 - acc: 0.53 - ETA: 12s - loss: 0.7170 - acc: 0.53 - ETA: 11s - loss: 0.7163 - acc: 0.53 - ETA: 11s - loss: 0.7156 - acc: 0.54 - ETA: 10s - loss: 0.7148 - acc: 0.54 - ETA: 10s - loss: 0.7145 - acc: 0.54 - ETA: 9s - loss: 0.7138 - acc: 0.5417 - ETA: 9s - loss: 0.7131 - acc: 0.542 - ETA: 8s - loss: 0.7124 - acc: 0.543 - ETA: 8s - loss: 0.7120 - acc: 0.543 - ETA: 7s - loss: 0.7114 - acc: 0.543 - ETA: 7s - loss: 0.7114 - acc: 0.543 - ETA: 6s - loss: 0.7110 - acc: 0.543 - ETA: 6s - loss: 0.7103 - acc: 0.544 - ETA: 5s - loss: 0.7098 - acc: 0.544 - ETA: 5s - loss: 0.7083 - acc: 0.547 - ETA: 4s - loss: 0.7067 - acc: 0.548 - ETA: 4s - loss: 0.7046 - acc: 0.550 - ETA: 4s - loss: 0.7030 - acc: 0.553 - ETA: 3s - loss: 0.7008 - acc: 0.555 - ETA: 3s - loss: 0.6972 - acc: 0.559 - ETA: 2s - loss: 0.6936 - acc: 0.563 - ETA: 2s - loss: 0.6903 - acc: 0.567 - ETA: 2s - loss: 0.6868 - acc: 0.571 - ETA: 1s - loss: 0.6834 - acc: 0.574 - ETA: 1s - loss: 0.6821 - acc: 0.577 - ETA: 0s - loss: 0.6793 - acc: 0.580 - ETA: 0s - loss: 0.6760 - acc: 0.583 - ETA: 0s - loss: 0.6743 - acc: 0.585 - 28s 2ms/step - loss: 0.6731 - acc: 0.5870 - val_loss: 0.4499 - val_acc: 0.8067\n",
      "Epoch 2/2\n",
      "17093/17093 [==============================] - ETA: 18s - loss: 0.4182 - acc: 0.83 - ETA: 17s - loss: 0.4257 - acc: 0.83 - ETA: 17s - loss: 0.4104 - acc: 0.83 - ETA: 17s - loss: 0.4137 - acc: 0.83 - ETA: 16s - loss: 0.4232 - acc: 0.82 - ETA: 16s - loss: 0.4208 - acc: 0.82 - ETA: 16s - loss: 0.4180 - acc: 0.82 - ETA: 16s - loss: 0.4160 - acc: 0.82 - ETA: 15s - loss: 0.4075 - acc: 0.83 - ETA: 15s - loss: 0.3985 - acc: 0.83 - ETA: 15s - loss: 0.3954 - acc: 0.83 - ETA: 15s - loss: 0.3871 - acc: 0.84 - ETA: 14s - loss: 0.3875 - acc: 0.84 - ETA: 14s - loss: 0.3907 - acc: 0.83 - ETA: 14s - loss: 0.3906 - acc: 0.83 - ETA: 13s - loss: 0.3864 - acc: 0.83 - ETA: 13s - loss: 0.3862 - acc: 0.83 - ETA: 13s - loss: 0.3854 - acc: 0.83 - ETA: 13s - loss: 0.3861 - acc: 0.83 - ETA: 12s - loss: 0.3878 - acc: 0.83 - ETA: 12s - loss: 0.3883 - acc: 0.83 - ETA: 12s - loss: 0.3905 - acc: 0.83 - ETA: 12s - loss: 0.3895 - acc: 0.83 - ETA: 11s - loss: 0.3856 - acc: 0.83 - ETA: 11s - loss: 0.3868 - acc: 0.83 - ETA: 11s - loss: 0.3857 - acc: 0.83 - ETA: 11s - loss: 0.3870 - acc: 0.83 - ETA: 10s - loss: 0.3871 - acc: 0.83 - ETA: 10s - loss: 0.3860 - acc: 0.83 - ETA: 10s - loss: 0.3841 - acc: 0.83 - ETA: 9s - loss: 0.3826 - acc: 0.8397 - ETA: 9s - loss: 0.3805 - acc: 0.840 - ETA: 9s - loss: 0.3786 - acc: 0.841 - ETA: 9s - loss: 0.3773 - acc: 0.842 - ETA: 8s - loss: 0.3764 - acc: 0.843 - ETA: 8s - loss: 0.3773 - acc: 0.843 - ETA: 8s - loss: 0.3775 - acc: 0.842 - ETA: 8s - loss: 0.3789 - acc: 0.842 - ETA: 7s - loss: 0.3794 - acc: 0.841 - ETA: 7s - loss: 0.3782 - acc: 0.841 - ETA: 7s - loss: 0.3790 - acc: 0.841 - ETA: 7s - loss: 0.3783 - acc: 0.842 - ETA: 6s - loss: 0.3826 - acc: 0.840 - ETA: 6s - loss: 0.3828 - acc: 0.840 - ETA: 6s - loss: 0.3829 - acc: 0.840 - ETA: 6s - loss: 0.3818 - acc: 0.840 - ETA: 5s - loss: 0.3811 - acc: 0.841 - ETA: 5s - loss: 0.3822 - acc: 0.841 - ETA: 5s - loss: 0.3810 - acc: 0.841 - ETA: 4s - loss: 0.3810 - acc: 0.841 - ETA: 4s - loss: 0.3810 - acc: 0.841 - ETA: 4s - loss: 0.3793 - acc: 0.842 - ETA: 4s - loss: 0.3783 - acc: 0.842 - ETA: 3s - loss: 0.3771 - acc: 0.842 - ETA: 3s - loss: 0.3773 - acc: 0.842 - ETA: 3s - loss: 0.3777 - acc: 0.842 - ETA: 3s - loss: 0.3771 - acc: 0.842 - ETA: 2s - loss: 0.3771 - acc: 0.841 - ETA: 2s - loss: 0.3766 - acc: 0.841 - ETA: 2s - loss: 0.3762 - acc: 0.841 - ETA: 1s - loss: 0.3766 - acc: 0.840 - ETA: 1s - loss: 0.3763 - acc: 0.841 - ETA: 1s - loss: 0.3747 - acc: 0.841 - ETA: 1s - loss: 0.3736 - acc: 0.841 - ETA: 0s - loss: 0.3729 - acc: 0.842 - ETA: 0s - loss: 0.3720 - acc: 0.842 - ETA: 0s - loss: 0.3714 - acc: 0.843 - ETA: 0s - loss: 0.3714 - acc: 0.842 - 19s 1ms/step - loss: 0.3711 - acc: 0.8432 - val_loss: 0.4153 - val_acc: 0.8528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x291f2fd4198>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml.fit(x_train,y_train,validation_data=[x_val,y_val],epochs=2,batch_size=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=ml.predict_classes(x_val)\n",
    "y_pred1=ml.predict_classes(x_train)\n",
    "y_pred2=ml.predict_classes(x_test)\n",
    "y_val1=np.argmax(y_val,axis=1)\n",
    "y_train1=np.argmax(y_train,axis=1)\n",
    "str1='Training accuracy = {s2} \\nValidation accuracy= {s1} \\nTesting Accuracy= {s3}'.format(s1=accuracy_score(y_val1,y_pred),s2=accuracy_score(y_train1,y_pred1),s3=accuracy_score(y_test,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- LSTM --------------\n",
      "\n",
      "Training accuracy = 0.932486982975487 \n",
      "Validation accuracy= 0.8528310715956949 \n",
      "Testing Accuracy= 0.8464994384125796\n"
     ]
    }
   ],
   "source": [
    "print('--------------- LSTM --------------\\n')\n",
    "print(str1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1=load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=m1.predict_classes(x_val)\n",
    "y_pred1=m1.predict_classes(x_train)\n",
    "y_pred2=m1.predict_classes(x_test)\n",
    "y_val1=np.argmax(y_val,axis=1)\n",
    "y_train1=np.argmax(y_train,axis=1)\n",
    "str1='Training accuracy = {s2} \\nValidation accuracy= {s1} \\nTesting Accuracy= {s3}'.format(s1=accuracy_score(y_val1,y_pred),s2=accuracy_score(y_train1,y_pred1),s3=accuracy_score(y_test,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.85      0.86      3025\n",
      "           1       0.81      0.84      0.83      2317\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      5342\n",
      "   macro avg       0.84      0.85      0.84      5342\n",
      "weighted avg       0.85      0.85      0.85      5342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2578  447]\n",
      " [ 373 1944]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(sent):\n",
    "    sent1=clean_sentences(sent)\n",
    "    senti=tokenizer.texts_to_sequences(sent1)\n",
    "    senti=sequence.pad_sequences(senti,maxlen=len_max)\n",
    "    return senti\n",
    "def predict_value(senten):\n",
    "    di={'headline':senten}\n",
    "    pd1=pd.DataFrame(di,index=[0])\n",
    "    #print(pd1.head())\n",
    "    s=ml.predict_proba(process(pd1))\n",
    "    print('The model is {s1}% confident that the sentence is sarcastic'.format(s1=(s[0][1]*100).round(decimals=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2528.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is 97.42% confident that the sentence is sarcastic\n"
     ]
    }
   ],
   "source": [
    "s=predict_value('Cancer cures smoking')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
